{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":800230,"sourceType":"datasetVersion","datasetId":1305},{"sourceId":4295,"sourceType":"modelInstanceVersion","modelInstanceId":3090}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install peft","metadata":{"execution":{"iopub.status.busy":"2024-05-04T07:12:13.649212Z","iopub.execute_input":"2024-05-04T07:12:13.649520Z","iopub.status.idle":"2024-05-04T07:12:26.388491Z","shell.execute_reply.started":"2024-05-04T07:12:13.649489Z","shell.execute_reply":"2024-05-04T07:12:26.387380Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Collecting peft\n  Downloading peft-0.10.0-py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from peft) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from peft) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from peft) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from peft) (6.0.1)\nRequirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.10/site-packages (from peft) (2.1.2)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (from peft) (4.39.3)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from peft) (4.66.1)\nRequirement already satisfied: accelerate>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from peft) (0.29.3)\nRequirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from peft) (0.4.3)\nRequirement already satisfied: huggingface-hub>=0.17.0 in /opt/conda/lib/python3.10/site-packages (from peft) (0.22.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (3.13.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (2024.2.0)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (2.31.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->peft) (3.1.1)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.1.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (2023.12.25)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (0.15.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (2024.2.2)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\nDownloading peft-0.10.0-py3-none-any.whl (199 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.1/199.1 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: peft\nSuccessfully installed peft-0.10.0\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install trl","metadata":{"execution":{"iopub.status.busy":"2024-05-04T07:12:26.389958Z","iopub.execute_input":"2024-05-04T07:12:26.390309Z","iopub.status.idle":"2024-05-04T07:12:39.702032Z","shell.execute_reply.started":"2024-05-04T07:12:26.390278Z","shell.execute_reply":"2024-05-04T07:12:39.700914Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Collecting trl\n  Downloading trl-0.8.6-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: torch>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from trl) (2.1.2)\nRequirement already satisfied: transformers>=4.31.0 in /opt/conda/lib/python3.10/site-packages (from trl) (4.39.3)\nRequirement already satisfied: numpy>=1.18.2 in /opt/conda/lib/python3.10/site-packages (from trl) (1.26.4)\nRequirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (from trl) (0.29.3)\nRequirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (from trl) (2.18.0)\nCollecting tyro>=0.5.11 (from trl)\n  Downloading tyro-0.8.3-py3-none-any.whl.metadata (7.9 kB)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl) (2024.2.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.31.0->trl) (0.22.2)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.31.0->trl) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.31.0->trl) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.31.0->trl) (2023.12.25)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers>=4.31.0->trl) (2.31.0)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.31.0->trl) (0.15.2)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.31.0->trl) (0.4.3)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.31.0->trl) (4.66.1)\nRequirement already satisfied: docstring-parser>=0.14.1 in /opt/conda/lib/python3.10/site-packages (from tyro>=0.5.11->trl) (0.15)\nRequirement already satisfied: rich>=11.1.0 in /opt/conda/lib/python3.10/site-packages (from tyro>=0.5.11->trl) (13.7.0)\nCollecting shtab>=1.5.6 (from tyro>=0.5.11->trl)\n  Downloading shtab-1.7.1-py3-none-any.whl.metadata (7.3 kB)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate->trl) (5.9.3)\nRequirement already satisfied: pyarrow>=12.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets->trl) (15.0.2)\nRequirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets->trl) (0.6)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets->trl) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets->trl) (2.1.4)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets->trl) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets->trl) (0.70.16)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets->trl) (3.9.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->trl) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->trl) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->trl) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->trl) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->trl) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->trl) (4.0.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers>=4.31.0->trl) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.31.0->trl) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.31.0->trl) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.31.0->trl) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.31.0->trl) (2024.2.2)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich>=11.1.0->tyro>=0.5.11->trl) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich>=11.1.0->tyro>=0.5.11->trl) (2.17.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.4.0->trl) (2.1.3)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->trl) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->trl) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->trl) (2023.4)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.4.0->trl) (1.3.0)\nRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro>=0.5.11->trl) (0.1.2)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets->trl) (1.16.0)\nDownloading trl-0.8.6-py3-none-any.whl (245 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m245.2/245.2 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tyro-0.8.3-py3-none-any.whl (102 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.0/102.0 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading shtab-1.7.1-py3-none-any.whl (14 kB)\nInstalling collected packages: shtab, tyro, trl\nSuccessfully installed shtab-1.7.1 trl-0.8.6 tyro-0.8.3\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install bitsandbytes","metadata":{"execution":{"iopub.status.busy":"2024-05-04T07:11:57.129173Z","iopub.execute_input":"2024-05-04T07:11:57.130057Z","iopub.status.idle":"2024-05-04T07:12:13.647130Z","shell.execute_reply.started":"2024-05-04T07:11:57.130007Z","shell.execute_reply":"2024-05-04T07:12:13.645983Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Collecting bitsandbytes\n  Downloading bitsandbytes-0.43.1-py3-none-manylinux_2_24_x86_64.whl.metadata (2.2 kB)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from bitsandbytes) (2.1.2)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from bitsandbytes) (1.26.4)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (2024.2.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->bitsandbytes) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->bitsandbytes) (1.3.0)\nDownloading bitsandbytes-0.43.1-py3-none-manylinux_2_24_x86_64.whl (119.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.8/119.8 MB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: bitsandbytes\nSuccessfully installed bitsandbytes-0.43.1\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install --upgrade pip","metadata":{"execution":{"iopub.status.busy":"2024-05-04T07:11:17.914901Z","iopub.execute_input":"2024-05-04T07:11:17.915514Z","iopub.status.idle":"2024-05-04T07:11:42.673559Z","shell.execute_reply.started":"2024-05-04T07:11:17.915487Z","shell.execute_reply":"2024-05-04T07:11:42.672451Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: pip in /opt/conda/lib/python3.10/site-packages (23.3.2)\nCollecting pip\n  Downloading pip-24.0-py3-none-any.whl.metadata (3.6 kB)\nDownloading pip-24.0-py3-none-any.whl (2.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: pip\n  Attempting uninstall: pip\n    Found existing installation: pip 23.3.2\n    Uninstalling pip-23.3.2:\n      Successfully uninstalled pip-23.3.2\nSuccessfully installed pip-24.0\n","output_type":"stream"}]},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nimport bz2\nimport csv\nimport re\nimport gc\n\nfrom tqdm import tqdm\nimport bitsandbytes as bnb\nimport torch\nimport torch.nn as nn\nimport transformers\nfrom datasets import Dataset\nfrom peft import LoraConfig, PeftConfig\nfrom trl import SFTTrainer\nfrom trl import setup_chat_format\n\n\n\nimport matplotlib.pyplot as plt\nfrom tensorflow.python.keras import models, layers, optimizers\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing import text\nfrom tensorflow.keras.preprocessing.text import Tokenizer, text_to_word_sequence\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom sklearn.metrics import f1_score, roc_auc_score, accuracy_score\n\nfrom tensorflow.keras.preprocessing.text import Tokenizer\n\nfrom transformers import PreTrainedTokenizerFast\n\n\n\n\n%matplotlib inline\n\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"execution":{"iopub.status.busy":"2024-05-04T07:12:39.705060Z","iopub.execute_input":"2024-05-04T07:12:39.705774Z","iopub.status.idle":"2024-05-04T07:12:56.292071Z","shell.execute_reply.started":"2024-05-04T07:12:39.705743Z","shell.execute_reply":"2024-05-04T07:12:56.291289Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":"2024-05-04 07:12:48.774355: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-05-04 07:12:48.774446: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-05-04 07:12:48.908261: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"base_dir = (\"/kaggle/input/amazonreviews/\")\n\nfor fname in ['test.ft.txt.bz2', 'train.ft.txt.bz2']:\n    ifname = base_dir + fname\n    print(ifname)\n    \n    data = None\n    with open(ifname, 'rb') as ifile:\n        data = ifile.read()\n    print('Data read, {} bytes'.format(len(data)))","metadata":{"execution":{"iopub.status.busy":"2024-05-04T07:12:56.293231Z","iopub.execute_input":"2024-05-04T07:12:56.293880Z","iopub.status.idle":"2024-05-04T07:13:02.936512Z","shell.execute_reply.started":"2024-05-04T07:12:56.293854Z","shell.execute_reply":"2024-05-04T07:13:02.935666Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"/kaggle/input/amazonreviews/test.ft.txt.bz2\nData read, 52653659 bytes\n/kaggle/input/amazonreviews/train.ft.txt.bz2\nData read, 464275989 bytes\n","output_type":"stream"}]},{"cell_type":"code","source":"def get_labels_and_texts(file):\n    labels = []\n    texts = []\n    for line in bz2.BZ2File(file):\n        x = line.decode(\"utf-8\")\n        labels.append(int(x[9]) - 1)\n        texts.append(x[10:].strip())\n    return np.array(labels), texts\ntrain_labels, train_texts = get_labels_and_texts(base_dir + 'train.ft.txt.bz2')\ntest_labels, test_texts = get_labels_and_texts(base_dir + 'test.ft.txt.bz2')","metadata":{"execution":{"iopub.status.busy":"2024-05-04T07:13:02.937679Z","iopub.execute_input":"2024-05-04T07:13:02.937991Z","iopub.status.idle":"2024-05-04T07:14:50.553561Z","shell.execute_reply.started":"2024-05-04T07:13:02.937965Z","shell.execute_reply":"2024-05-04T07:14:50.552724Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"print(\"test_labels:\", test_labels)\nprint(\"train_labels:\", train_labels)\nprint(type(train_labels)) # numpy\nprint(type(test_labels)) # numpy\n\n\nprint(\"train_texts 길이:\", len(train_texts)) # 3600000\nprint(\"test_texts 길이:\", len(test_texts)) # 400000","metadata":{"execution":{"iopub.status.busy":"2024-05-04T07:14:50.554804Z","iopub.execute_input":"2024-05-04T07:14:50.555279Z","iopub.status.idle":"2024-05-04T07:14:50.562139Z","shell.execute_reply.started":"2024-05-04T07:14:50.555243Z","shell.execute_reply":"2024-05-04T07:14:50.561191Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"test_labels: [1 1 0 ... 0 1 0]\ntrain_labels: [1 1 1 ... 0 0 1]\n<class 'numpy.ndarray'>\n<class 'numpy.ndarray'>\ntrain_texts 길이: 3600000\ntest_texts 길이: 400000\n","output_type":"stream"}]},{"cell_type":"code","source":"type(train_texts) # list\ntype(train_labels) # numpy\n\n# type(train_labels) # numpy\ntrain_labels2 = train_labels.tolist()\ntype(train_labels2) # list\ntrain_labels3 = list(map(str, train_labels2))\ntype(train_labels3) # list","metadata":{"execution":{"iopub.status.busy":"2024-05-04T07:14:50.563191Z","iopub.execute_input":"2024-05-04T07:14:50.563444Z","iopub.status.idle":"2024-05-04T07:14:51.223592Z","shell.execute_reply.started":"2024-05-04T07:14:50.563423Z","shell.execute_reply":"2024-05-04T07:14:51.222591Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"list"},"metadata":{}}]},{"cell_type":"code","source":"type(test_texts) # list\ntype(test_labels) # numpy\n\n# type(train_labels) # numpy\ntest_labels2 = test_labels.tolist()\ntype(test_labels2) # list\ntest_labels3 = list(map(str, test_labels2))\ntype(test_labels3) # list","metadata":{"execution":{"iopub.status.busy":"2024-05-04T07:14:51.224619Z","iopub.execute_input":"2024-05-04T07:14:51.224917Z","iopub.status.idle":"2024-05-04T07:14:51.484946Z","shell.execute_reply.started":"2024-05-04T07:14:51.224893Z","shell.execute_reply":"2024-05-04T07:14:51.483912Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"list"},"metadata":{}}]},{"cell_type":"code","source":"train_df = pd.Series([train_texts, train_labels3], index=['texts', 'labels'])\ntrain_df","metadata":{"execution":{"iopub.status.busy":"2024-05-04T07:14:51.488766Z","iopub.execute_input":"2024-05-04T07:14:51.489126Z","iopub.status.idle":"2024-05-04T07:14:51.504857Z","shell.execute_reply.started":"2024-05-04T07:14:51.489091Z","shell.execute_reply":"2024-05-04T07:14:51.503993Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"texts     [Stuning even for the non-gamer: This sound tr...\nlabels    [1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, ...\ndtype: object"},"metadata":{}}]},{"cell_type":"code","source":"test_df = pd.Series([test_texts, test_labels3], index=['texts', 'labels'])\ntest_df","metadata":{"execution":{"iopub.status.busy":"2024-05-04T07:14:51.505787Z","iopub.execute_input":"2024-05-04T07:14:51.506091Z","iopub.status.idle":"2024-05-04T07:14:51.519340Z","shell.execute_reply.started":"2024-05-04T07:14:51.506057Z","shell.execute_reply":"2024-05-04T07:14:51.518375Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"texts     [Great CD: My lovely Pat has one of the GREAT ...\nlabels    [1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, ...\ndtype: object"},"metadata":{}}]},{"cell_type":"code","source":"combined_data = []\nfor text, label in zip(train_df.texts, train_df.labels):\n    combined_data.append((text.strip(\"'\"), label.replace(',', '')))\n    \n\n# Convert to DataFrame\ntrain = pd.DataFrame(combined_data, columns=['texts', 'labels'])","metadata":{"execution":{"iopub.status.busy":"2024-05-04T07:14:51.520499Z","iopub.execute_input":"2024-05-04T07:14:51.520784Z","iopub.status.idle":"2024-05-04T07:14:55.198798Z","shell.execute_reply.started":"2024-05-04T07:14:51.520761Z","shell.execute_reply":"2024-05-04T07:14:55.197956Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# Print the DataFrame\n# train.head()\n# train.tail()  # 3599999\nlen(train)  # 3600000","metadata":{"execution":{"iopub.status.busy":"2024-05-04T07:14:55.199861Z","iopub.execute_input":"2024-05-04T07:14:55.200174Z","iopub.status.idle":"2024-05-04T07:14:55.205922Z","shell.execute_reply.started":"2024-05-04T07:14:55.200150Z","shell.execute_reply":"2024-05-04T07:14:55.205007Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"3600000"},"metadata":{}}]},{"cell_type":"code","source":"combined_data2 = []\nfor text, label in zip(test_df.texts, test_df.labels):\n    combined_data2.append((text.strip(\"'\"), label.replace(',', '')))\n    \n\n# Convert to DataFrame\ntest = pd.DataFrame(combined_data2, columns=['texts', 'labels'])\n\n# Print the DataFrame\ntest.tail()","metadata":{"execution":{"iopub.status.busy":"2024-05-04T07:14:55.207095Z","iopub.execute_input":"2024-05-04T07:14:55.207374Z","iopub.status.idle":"2024-05-04T07:14:55.600198Z","shell.execute_reply.started":"2024-05-04T07:14:55.207352Z","shell.execute_reply":"2024-05-04T07:14:55.599193Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"                                                    texts labels\n399995  Unbelievable- In a Bad Way: We bought this Tho...      0\n399996  Almost Great, Until it Broke...: My son reciev...      0\n399997  Disappointed !!!: I bought this toy for my son...      0\n399998  Classic Jessica Mitford: This is a compilation...      1\n399999  Comedy Scene, and Not Heard: This DVD will be ...      0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>texts</th>\n      <th>labels</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>399995</th>\n      <td>Unbelievable- In a Bad Way: We bought this Tho...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>399996</th>\n      <td>Almost Great, Until it Broke...: My son reciev...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>399997</th>\n      <td>Disappointed !!!: I bought this toy for my son...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>399998</th>\n      <td>Classic Jessica Mitford: This is a compilation...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>399999</th>\n      <td>Comedy Scene, and Not Heard: This DVD will be ...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Print the DataFrame\n# test.head()\n# test.tail()  # 399999\nlen(test) # 400000","metadata":{"execution":{"iopub.status.busy":"2024-05-04T07:14:55.601467Z","iopub.execute_input":"2024-05-04T07:14:55.601762Z","iopub.status.idle":"2024-05-04T07:14:55.607804Z","shell.execute_reply.started":"2024-05-04T07:14:55.601737Z","shell.execute_reply":"2024-05-04T07:14:55.606852Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"400000"},"metadata":{}}]},{"cell_type":"code","source":"train_data = train.drop_duplicates(inplace=False)\ntrain_data = train_data.dropna(how='any')\ntrain_data","metadata":{"execution":{"iopub.status.busy":"2024-05-04T07:14:55.608961Z","iopub.execute_input":"2024-05-04T07:14:55.609369Z","iopub.status.idle":"2024-05-04T07:15:05.416049Z","shell.execute_reply.started":"2024-05-04T07:14:55.609346Z","shell.execute_reply":"2024-05-04T07:15:05.415132Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"                                                     texts labels\n0        Stuning even for the non-gamer: This sound tra...      1\n1        The best soundtrack ever to anything.: I'm rea...      1\n2        Amazing!: This soundtrack is my favorite music...      1\n3        Excellent Soundtrack: I truly like this soundt...      1\n4        Remember, Pull Your Jaw Off The Floor After He...      1\n...                                                    ...    ...\n3599995  Don't do it!!: The high chair looks great when...      0\n3599996  Looks nice, low functionality: I have used thi...      0\n3599997  compact, but hard to clean: We have a small ho...      0\n3599998  what is it saying?: not sure what this book is...      0\n3599999  Makes My Blood Run Red-White-And-Blue: I agree...      1\n\n[3600000 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>texts</th>\n      <th>labels</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Stuning even for the non-gamer: This sound tra...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>The best soundtrack ever to anything.: I'm rea...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Amazing!: This soundtrack is my favorite music...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Excellent Soundtrack: I truly like this soundt...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Remember, Pull Your Jaw Off The Floor After He...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3599995</th>\n      <td>Don't do it!!: The high chair looks great when...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3599996</th>\n      <td>Looks nice, low functionality: I have used thi...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3599997</th>\n      <td>compact, but hard to clean: We have a small ho...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3599998</th>\n      <td>what is it saying?: not sure what this book is...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3599999</th>\n      <td>Makes My Blood Run Red-White-And-Blue: I agree...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>3600000 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# train_data = train_data.astype({'texts':'str','labels':'int32'})\n# print(train_data.dtypes)","metadata":{"execution":{"iopub.status.busy":"2024-05-04T07:15:05.417991Z","iopub.execute_input":"2024-05-04T07:15:05.419017Z","iopub.status.idle":"2024-05-04T07:15:05.422999Z","shell.execute_reply.started":"2024-05-04T07:15:05.418961Z","shell.execute_reply":"2024-05-04T07:15:05.422078Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"train_data.groupby(by=['labels']).count()","metadata":{"execution":{"iopub.status.busy":"2024-05-04T07:15:05.424302Z","iopub.execute_input":"2024-05-04T07:15:05.424577Z","iopub.status.idle":"2024-05-04T07:15:06.272498Z","shell.execute_reply.started":"2024-05-04T07:15:05.424554Z","shell.execute_reply":"2024-05-04T07:15:06.271560Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"          texts\nlabels         \n0       1800000\n1       1800000","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>texts</th>\n    </tr>\n    <tr>\n      <th>labels</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1800000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1800000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"test_data = test.drop_duplicates(inplace=False)\ntest_data = test_data.dropna(how='any')\ntest_data","metadata":{"execution":{"iopub.status.busy":"2024-05-04T07:15:06.273607Z","iopub.execute_input":"2024-05-04T07:15:06.273879Z","iopub.status.idle":"2024-05-04T07:15:06.921177Z","shell.execute_reply.started":"2024-05-04T07:15:06.273857Z","shell.execute_reply":"2024-05-04T07:15:06.920290Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"                                                    texts labels\n0       Great CD: My lovely Pat has one of the GREAT v...      1\n1       One of the best game music soundtracks - for a...      1\n2       Batteries died within a year ...: I bought thi...      0\n3       works fine, but Maha Energy is better: Check o...      1\n4       Great for the non-audiophile: Reviewed quite a...      1\n...                                                   ...    ...\n399995  Unbelievable- In a Bad Way: We bought this Tho...      0\n399996  Almost Great, Until it Broke...: My son reciev...      0\n399997  Disappointed !!!: I bought this toy for my son...      0\n399998  Classic Jessica Mitford: This is a compilation...      1\n399999  Comedy Scene, and Not Heard: This DVD will be ...      0\n\n[400000 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>texts</th>\n      <th>labels</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Great CD: My lovely Pat has one of the GREAT v...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>One of the best game music soundtracks - for a...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Batteries died within a year ...: I bought thi...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>works fine, but Maha Energy is better: Check o...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Great for the non-audiophile: Reviewed quite a...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>399995</th>\n      <td>Unbelievable- In a Bad Way: We bought this Tho...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>399996</th>\n      <td>Almost Great, Until it Broke...: My son reciev...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>399997</th>\n      <td>Disappointed !!!: I bought this toy for my son...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>399998</th>\n      <td>Classic Jessica Mitford: This is a compilation...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>399999</th>\n      <td>Comedy Scene, and Not Heard: This DVD will be ...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>400000 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# test_data = test_data.astype({'texts':'str','labels':'int32'})\n# print(test_data.dtypes)","metadata":{"execution":{"iopub.status.busy":"2024-05-04T07:15:06.922208Z","iopub.execute_input":"2024-05-04T07:15:06.922481Z","iopub.status.idle":"2024-05-04T07:15:06.926630Z","shell.execute_reply.started":"2024-05-04T07:15:06.922458Z","shell.execute_reply":"2024-05-04T07:15:06.925697Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"test_data.groupby(by=['labels']).count()","metadata":{"execution":{"iopub.status.busy":"2024-05-04T07:15:06.927755Z","iopub.execute_input":"2024-05-04T07:15:06.928093Z","iopub.status.idle":"2024-05-04T07:15:07.025276Z","shell.execute_reply.started":"2024-05-04T07:15:06.928064Z","shell.execute_reply":"2024-05-04T07:15:07.024399Z"},"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"         texts\nlabels        \n0       200000\n1       200000","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>texts</th>\n    </tr>\n    <tr>\n      <th>labels</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>200000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>200000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"X_train = train_data.texts\nX_test = train_data.labels\ny_test = test_data.texts\ny_true = test_data.labels","metadata":{"execution":{"iopub.status.busy":"2024-05-04T07:15:07.026656Z","iopub.execute_input":"2024-05-04T07:15:07.027050Z","iopub.status.idle":"2024-05-04T07:15:07.032082Z","shell.execute_reply.started":"2024-05-04T07:15:07.027004Z","shell.execute_reply":"2024-05-04T07:15:07.030996Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"X_test.iloc[0]","metadata":{"execution":{"iopub.status.busy":"2024-05-04T07:15:07.033252Z","iopub.execute_input":"2024-05-04T07:15:07.033589Z","iopub.status.idle":"2024-05-04T07:15:07.043787Z","shell.execute_reply.started":"2024-05-04T07:15:07.033559Z","shell.execute_reply":"2024-05-04T07:15:07.042907Z"},"trusted":true},"execution_count":25,"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"'1'"},"metadata":{}}]},{"cell_type":"markdown","source":"### Load the model","metadata":{}},{"cell_type":"code","source":"# !pip install -q -U \"transformers==4.36.2\" \"datasets==2.16.1\" \"accelerate==0.26.1\" \"bitsandbytes==0.42.0\"","metadata":{"execution":{"iopub.status.busy":"2024-05-04T07:15:07.045128Z","iopub.execute_input":"2024-05-04T07:15:07.045460Z","iopub.status.idle":"2024-05-04T07:15:07.052625Z","shell.execute_reply.started":"2024-05-04T07:15:07.045431Z","shell.execute_reply":"2024-05-04T07:15:07.051844Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"# !pip install --upgrade transformers","metadata":{"execution":{"iopub.status.busy":"2024-05-04T07:15:07.053544Z","iopub.execute_input":"2024-05-04T07:15:07.053806Z","iopub.status.idle":"2024-05-04T07:15:07.061869Z","shell.execute_reply.started":"2024-05-04T07:15:07.053785Z","shell.execute_reply":"2024-05-04T07:15:07.061210Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"working on {device}\")","metadata":{"execution":{"iopub.status.busy":"2024-05-04T07:15:07.062991Z","iopub.execute_input":"2024-05-04T07:15:07.063399Z","iopub.status.idle":"2024-05-04T07:15:07.072681Z","shell.execute_reply.started":"2024-05-04T07:15:07.063370Z","shell.execute_reply":"2024-05-04T07:15:07.071842Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"working on cuda:0\n","output_type":"stream"}]},{"cell_type":"code","source":"import time\nimport torch\nimport transformers\nfrom transformers import (AutoModelForCausalLM, \n                          AutoTokenizer, \n                          BitsAndBytesConfig, \n                          TrainingArguments, \n                          pipeline, \n                          logging)\nfrom sklearn.metrics import (accuracy_score, \n                             classification_report, \n                             confusion_matrix)\nfrom sklearn.model_selection import train_test_split\n\n\nfrom IPython.display import display, Markdown\n\nimport tensorflow as tf\nfrom tensorflow.keras.callbacks import EarlyStopping","metadata":{"execution":{"iopub.status.busy":"2024-05-04T07:15:07.154871Z","iopub.execute_input":"2024-05-04T07:15:07.155137Z","iopub.status.idle":"2024-05-04T07:15:07.160613Z","shell.execute_reply.started":"2024-05-04T07:15:07.155116Z","shell.execute_reply":"2024-05-04T07:15:07.159741Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"model_name = \"/kaggle/input/llama-2/pytorch/7b-hf/1\"\n\ncompute_dtype = getattr(torch, \"float16\")\n\nbnb_config = BitsAndBytesConfig(\n    load_in_4bit=True, \n    bnb_4bit_quant_type=\"nf4\", \n    bnb_4bit_compute_dtype=compute_dtype,\n    bnb_4bit_use_double_quant=True,\n)\n\n# Define early stopping callback\nearly_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)","metadata":{"execution":{"iopub.status.busy":"2024-05-04T07:15:07.161711Z","iopub.execute_input":"2024-05-04T07:15:07.161982Z","iopub.status.idle":"2024-05-04T07:15:07.173598Z","shell.execute_reply.started":"2024-05-04T07:15:07.161960Z","shell.execute_reply":"2024-05-04T07:15:07.172820Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(model_name, \n                                          trust_remote_code=True,\n                                         )\ntokenizer.pad_token = tokenizer.eos_token\ntokenizer.padding_side = \"right\"","metadata":{"execution":{"iopub.status.busy":"2024-05-04T07:15:07.174627Z","iopub.execute_input":"2024-05-04T07:15:07.174882Z","iopub.status.idle":"2024-05-04T07:15:07.376270Z","shell.execute_reply.started":"2024-05-04T07:15:07.174861Z","shell.execute_reply":"2024-05-04T07:15:07.375489Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"model = AutoModelForCausalLM.from_pretrained(\n    model_name,\n    device_map=device,\n    torch_dtype=compute_dtype,\n    quantization_config=bnb_config, \n    # early_stopping = early_stopping\n)\n\nmodel.config.use_cache = False\nmodel.config.pretraining_tp = 1\n\n\nmodel, tokenizer = setup_chat_format(model, tokenizer)","metadata":{"execution":{"iopub.status.busy":"2024-05-04T07:15:07.377226Z","iopub.execute_input":"2024-05-04T07:15:07.377482Z","iopub.status.idle":"2024-05-04T07:18:20.999495Z","shell.execute_reply.started":"2024-05-04T07:15:07.377461Z","shell.execute_reply":"2024-05-04T07:18:20.998653Z"},"trusted":true},"execution_count":33,"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"61370ff36f0f45e1b79cb085f33b362d"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:492: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:497: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:492: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:497: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"model","metadata":{"execution":{"iopub.status.busy":"2024-05-04T07:18:21.000627Z","iopub.execute_input":"2024-05-04T07:18:21.000923Z","iopub.status.idle":"2024-05-04T07:18:21.009544Z","shell.execute_reply.started":"2024-05-04T07:18:21.000900Z","shell.execute_reply":"2024-05-04T07:18:21.008653Z"},"trusted":true},"execution_count":34,"outputs":[{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"LlamaForCausalLM(\n  (model): LlamaModel(\n    (embed_tokens): Embedding(32003, 4096)\n    (layers): ModuleList(\n      (0-31): 32 x LlamaDecoderLayer(\n        (self_attn): LlamaSdpaAttention(\n          (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n          (k_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n          (v_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n          (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n          (rotary_emb): LlamaRotaryEmbedding()\n        )\n        (mlp): LlamaMLP(\n          (gate_proj): Linear4bit(in_features=4096, out_features=11008, bias=False)\n          (up_proj): Linear4bit(in_features=4096, out_features=11008, bias=False)\n          (down_proj): Linear4bit(in_features=11008, out_features=4096, bias=False)\n          (act_fn): SiLU()\n        )\n        (input_layernorm): LlamaRMSNorm()\n        (post_attention_layernorm): LlamaRMSNorm()\n      )\n    )\n    (norm): LlamaRMSNorm()\n  )\n  (lm_head): Linear(in_features=4096, out_features=32003, bias=False)\n)"},"metadata":{}}]},{"cell_type":"code","source":"def predict(test, model, tokenizer):\n    y_pred = []\n    for i in tqdm(range(len(X_test))):\n        prompt = X_test.iloc[i]     # [\"labels\"]  # texts\n        pipe = pipeline(task=\"text-generation\", \n                        model=model, \n                        tokenizer=tokenizer, \n                        max_new_tokens = 1, \n                        temperature = 0.0,\n                       )\n        result = pipe(prompt)\n        answer = result[0]['generated_text'].split(\"=\")[-1]\n        if \"positive\" in answer:\n            y_pred.append(\"positive\")\n        elif \"negative\" in answer:\n            y_pred.append(\"negative\")\n        elif \"neutral\" in answer:\n            y_pred.append(\"neutral\")\n        else:\n            y_pred.append(\"none\")\n    return y_pred","metadata":{"execution":{"iopub.status.busy":"2024-05-04T07:18:21.010834Z","iopub.execute_input":"2024-05-04T07:18:21.011217Z","iopub.status.idle":"2024-05-04T07:18:21.019745Z","shell.execute_reply.started":"2024-05-04T07:18:21.011186Z","shell.execute_reply":"2024-05-04T07:18:21.018905Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"def evaluate(y_true, y_pred):\n    labels = ['1', '0']\n    mapping = {'positive': 1, 'negative': 0}\n    def map_func(x):\n        return mapping.get(x, 1)\n    \n    y_true = np.vectorize(map_func)(y_true)\n    y_pred = np.vectorize(map_func)(y_pred)\n    \n    # Calculate accuracy\n    accuracy = accuracy_score(y_true=y_true, y_pred=y_pred)\n    print(f'Accuracy: {accuracy:.3f}')\n    \n    # Generate accuracy report\n    unique_labels = set(y_true)  # Get unique labels\n    \n    for label in unique_labels:\n        label_indices = [i for i in range(len(y_true)) \n                         if y_true[i] == label]\n        label_y_true = [y_true[i] for i in label_indices]\n        label_y_pred = [y_pred[i] for i in label_indices]\n        accuracy = accuracy_score(label_y_true, label_y_pred)\n        print(f'Accuracy for label {label}: {accuracy:.3f}')\n        \n    # Generate classification report\n    class_report = classification_report(y_true=y_true, y_pred=y_pred)\n    print('\\nClassification Report:')\n    print(class_report)\n    \n    # Generate confusion matrix\n    conf_matrix = confusion_matrix(y_true=y_true, y_pred=y_pred, labels=[0, 1, 2])\n    print('\\nConfusion Matrix:')\n    print(conf_matrix)","metadata":{"execution":{"iopub.status.busy":"2024-05-04T07:18:21.020818Z","iopub.execute_input":"2024-05-04T07:18:21.021127Z","iopub.status.idle":"2024-05-04T07:18:21.035013Z","shell.execute_reply.started":"2024-05-04T07:18:21.021105Z","shell.execute_reply":"2024-05-04T07:18:21.034239Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"y_pred = predict(test_data.texts, model, tokenizer)","metadata":{"execution":{"iopub.status.busy":"2024-05-04T07:18:21.036155Z","iopub.execute_input":"2024-05-04T07:18:21.036691Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"  0%|          | 0/3600000 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:492: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n  warnings.warn(\n  1%|          | 27044/3600000 [1:43:22<227:30:58,  4.36it/s]","output_type":"stream"}]},{"cell_type":"code","source":"evaluate(y_true, y_pred)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"output_dir=\"trained_weigths\"\n\npeft_config = LoraConfig(\n        lora_alpha=16, \n        lora_dropout=0.1,\n        r=64,\n        bias=\"none\",\n        target_modules=\"all-linear\",\n        task_type=\"CAUSAL_LM\",\n)\n\ntraining_arguments = TrainingArguments(\n    output_dir=output_dir,                    # directory to save and repository id\n    num_train_epochs=3,                       # number of training epochs\n    per_device_train_batch_size=1,            # batch size per device during training\n    gradient_accumulation_steps=8,            # number of steps before performing a backward/update pass\n    gradient_checkpointing=True,              # use gradient checkpointing to save memory\n    optim=\"paged_adamw_32bit\",\n    save_steps=0,\n    logging_steps=25,                         # log every 10 steps\n    learning_rate=2e-4,                       # learning rate, based on QLoRA paper\n    weight_decay=0.001,\n    fp16=True,\n    bf16=False,\n    max_grad_norm=0.3,                        # max gradient norm based on QLoRA paper\n    max_steps=-1,\n    warmup_ratio=0.03,                        # warmup ratio based on QLoRA paper\n    group_by_length=True,\n    lr_scheduler_type=\"cosine\",               # use cosine learning rate scheduler\n    report_to=\"tensorboard\",                  # report metrics to tensorboard\n    evaluation_strategy=\"epoch\"               # save checkpoint every epoch\n)\n\ntrainer = SFTTrainer(\n    model=model,\n    args=training_arguments,\n    train_dataset=train_data,\n    eval_dataset=eval_data,\n    peft_config=peft_config,\n    dataset_text_field=\"text\",\n    tokenizer=tokenizer,\n    max_seq_length=1024,\n    packing=False,\n    dataset_kwargs={\n        \"add_special_tokens\": False,\n        \"append_concat_token\": False,\n    }\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train model\ntrainer.train()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Save trained model and tokenizer\ntrainer.save_model()\ntokenizer.save_pretrained(output_dir)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}